import json
import queue
import threading
import time
from datetime import datetime
import traceback
import pytz

from commonbaby.helpers.helper_str import substring
from commonbaby.httpaccess.httpaccess import HttpAccess

from datacontract.automateddataset import EAutoType
from idownclient.automated.autopluginbase import AutoPluginBase


class Exploit(AutoPluginBase):
    tasktype = EAutoType.EXPDB

    def __init__(self):
        AutoPluginBase.__init__(self)
        self.ha = HttpAccess(0.5)
        self.ha._managedCookie.add_cookies('.exploit-db.com',
                                           '_ga=GA1.3.659193532.1562029495; _gid=GA1.3.817890876.1562029495; _gat=1; XSRF-TOKEN=eyJpdiI6IkRQd3M1RHljcnhEM2hTVzhiMlcyV2c9PSIsInZhbHVlIjoiNzAwQVdWWFR3ck9oenBHWUd2a2NENTdrNXRqeWtOMU9iWk9pRGRxdVRFcGJyMmc0Q3gwQzBjbVg2bEdDWU5HTSIsIm1hYyI6IjFlMjRkMTcxMmFhODE1NzRmMDc0YWJlZTUzZTRlYTlmZjMyYTU1NDZjMjE5NjdkOTkzMGFjNDZlMzBhMWVjMjIifQ%3D%3D; exploit_database_session=eyJpdiI6IkE0QmJ3alZ3S0RFd3FHcnhQOTQzVGc9PSIsInZhbHVlIjoiYkpDNnh5azdtcmlOYms5cW5sMW9DUnhXYmhmSk9iZlVQa3pxOUVwUEpxQXhUeThMZUF3ZVBpMGRURzNcL1grNHAiLCJtYWMiOiIyODAzMmJjNjUzMWYyYzA0NmY0ZTYwMzFhYjg1YWUyOTc0OTMzNzBhYmYyZDc2MTkwZDYzYWY5Y2M5ZDhhMDI1In0%3D')
        self.page_queue = queue.Queue()

        self.detailsuffix = 'iscan_expdb'

        # 带文件体的回馈
        self.scriptsuffix = 'iscan_expdb_exp'
        self.sourcecodesuffix = 'iscan_expdb_app'

    def get_url(self):
        draw = 1
        start = 0
        t = int(datetime.now(pytz.timezone('Asia/Shanghai')).timestamp() * 1000)
        url = f'https://www.exploit-db.com/?draw={draw}&columns%5B0%5D%5Bdata%5D=date_published&columns%5B0%5D%5Bname%5D=date_published&columns%5B0%5D%5Bsearchable%5D=true&columns%5B0%5D%5Borderable%5D=true&columns%5B0%5D%5Bsearch%5D%5Bvalue%5D=&columns%5B0%5D%5Bsearch%5D%5Bregex%5D=false&columns%5B1%5D%5Bdata%5D=download&columns%5B1%5D%5Bname%5D=download&columns%5B1%5D%5Bsearchable%5D=false&columns%5B1%5D%5Borderable%5D=false&columns%5B1%5D%5Bsearch%5D%5Bvalue%5D=&columns%5B1%5D%5Bsearch%5D%5Bregex%5D=false&columns%5B2%5D%5Bdata%5D=application_md5&columns%5B2%5D%5Bname%5D=application_md5&columns%5B2%5D%5Bsearchable%5D=true&columns%5B2%5D%5Borderable%5D=false&columns%5B2%5D%5Bsearch%5D%5Bvalue%5D=&columns%5B2%5D%5Bsearch%5D%5Bregex%5D=false&columns%5B3%5D%5Bdata%5D=verified&columns%5B3%5D%5Bname%5D=verified&columns%5B3%5D%5Bsearchable%5D=true&columns%5B3%5D%5Borderable%5D=false&columns%5B3%5D%5Bsearch%5D%5Bvalue%5D=&columns%5B3%5D%5Bsearch%5D%5Bregex%5D=false&columns%5B4%5D%5Bdata%5D=description&columns%5B4%5D%5Bname%5D=description&columns%5B4%5D%5Bsearchable%5D=true&columns%5B4%5D%5Borderable%5D=false&columns%5B4%5D%5Bsearch%5D%5Bvalue%5D=&columns%5B4%5D%5Bsearch%5D%5Bregex%5D=false&columns%5B5%5D%5Bdata%5D=type_id&columns%5B5%5D%5Bname%5D=type_id&columns%5B5%5D%5Bsearchable%5D=true&columns%5B5%5D%5Borderable%5D=false&columns%5B5%5D%5Bsearch%5D%5Bvalue%5D=&columns%5B5%5D%5Bsearch%5D%5Bregex%5D=false&columns%5B6%5D%5Bdata%5D=platform_id&columns%5B6%5D%5Bname%5D=platform_id&columns%5B6%5D%5Bsearchable%5D=true&columns%5B6%5D%5Borderable%5D=false&columns%5B6%5D%5Bsearch%5D%5Bvalue%5D=&columns%5B6%5D%5Bsearch%5D%5Bregex%5D=false&columns%5B7%5D%5Bdata%5D=author_id&columns%5B7%5D%5Bname%5D=author_id&columns%5B7%5D%5Bsearchable%5D=false&columns%5B7%5D%5Borderable%5D=false&columns%5B7%5D%5Bsearch%5D%5Bvalue%5D=&columns%5B7%5D%5Bsearch%5D%5Bregex%5D=false&columns%5B8%5D%5Bdata%5D=code&columns%5B8%5D%5Bname%5D=code.code&columns%5B8%5D%5Bsearchable%5D=true&columns%5B8%5D%5Borderable%5D=true&columns%5B8%5D%5Bsearch%5D%5Bvalue%5D=&columns%5B8%5D%5Bsearch%5D%5Bregex%5D=false&columns%5B9%5D%5Bdata%5D=id&columns%5B9%5D%5Bname%5D=id&columns%5B9%5D%5Bsearchable%5D=false&columns%5B9%5D%5Borderable%5D=true&columns%5B9%5D%5Bsearch%5D%5Bvalue%5D=&columns%5B9%5D%5Bsearch%5D%5Bregex%5D=false&order%5B0%5D%5Bcolumn%5D=9&order%5B0%5D%5Bdir%5D=desc&start={start}&length=120&search%5Bvalue%5D=&search%5Bregex%5D=false&author=&port=&type=&tag=&platform=&_={t}'
        headers = """
    accept: application/json, text/javascript, */*; q=0.01
    accept-encoding: gzip, deflate, br
    accept-language: zh-CN,zh;q=0.9
    cache-control: no-cache
    pragma: no-cache
    referer: https://www.exploit-db.com/
    user-agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36
    x-requested-with: XMLHttpRequest"""
        html = self.ha.getstring(url, headers=headers)
        jshtml = json.loads(html)
        total = jshtml['recordsTotal']
        max = int(total / 120) + 1
        for draw in range(1, max + 1):
            start = (draw - 1) * 120
            self.page_queue.put((draw, start))
        print('Got all page! start download!')

    def get_onepage(self, draw, start):
        t = int(datetime.now(pytz.timezone('Asia/Shanghai')).timestamp() * 1000)
        url = f'https://www.exploit-db.com/?draw={draw}&columns%5B0%5D%5Bdata%5D=date_published&columns%5B0%5D%5Bname%5D=date_published&columns%5B0%5D%5Bsearchable%5D=true&columns%5B0%5D%5Borderable%5D=true&columns%5B0%5D%5Bsearch%5D%5Bvalue%5D=&columns%5B0%5D%5Bsearch%5D%5Bregex%5D=false&columns%5B1%5D%5Bdata%5D=download&columns%5B1%5D%5Bname%5D=download&columns%5B1%5D%5Bsearchable%5D=false&columns%5B1%5D%5Borderable%5D=false&columns%5B1%5D%5Bsearch%5D%5Bvalue%5D=&columns%5B1%5D%5Bsearch%5D%5Bregex%5D=false&columns%5B2%5D%5Bdata%5D=application_md5&columns%5B2%5D%5Bname%5D=application_md5&columns%5B2%5D%5Bsearchable%5D=true&columns%5B2%5D%5Borderable%5D=false&columns%5B2%5D%5Bsearch%5D%5Bvalue%5D=&columns%5B2%5D%5Bsearch%5D%5Bregex%5D=false&columns%5B3%5D%5Bdata%5D=verified&columns%5B3%5D%5Bname%5D=verified&columns%5B3%5D%5Bsearchable%5D=true&columns%5B3%5D%5Borderable%5D=false&columns%5B3%5D%5Bsearch%5D%5Bvalue%5D=&columns%5B3%5D%5Bsearch%5D%5Bregex%5D=false&columns%5B4%5D%5Bdata%5D=description&columns%5B4%5D%5Bname%5D=description&columns%5B4%5D%5Bsearchable%5D=true&columns%5B4%5D%5Borderable%5D=false&columns%5B4%5D%5Bsearch%5D%5Bvalue%5D=&columns%5B4%5D%5Bsearch%5D%5Bregex%5D=false&columns%5B5%5D%5Bdata%5D=type_id&columns%5B5%5D%5Bname%5D=type_id&columns%5B5%5D%5Bsearchable%5D=true&columns%5B5%5D%5Borderable%5D=false&columns%5B5%5D%5Bsearch%5D%5Bvalue%5D=&columns%5B5%5D%5Bsearch%5D%5Bregex%5D=false&columns%5B6%5D%5Bdata%5D=platform_id&columns%5B6%5D%5Bname%5D=platform_id&columns%5B6%5D%5Bsearchable%5D=true&columns%5B6%5D%5Borderable%5D=false&columns%5B6%5D%5Bsearch%5D%5Bvalue%5D=&columns%5B6%5D%5Bsearch%5D%5Bregex%5D=false&columns%5B7%5D%5Bdata%5D=author_id&columns%5B7%5D%5Bname%5D=author_id&columns%5B7%5D%5Bsearchable%5D=false&columns%5B7%5D%5Borderable%5D=false&columns%5B7%5D%5Bsearch%5D%5Bvalue%5D=&columns%5B7%5D%5Bsearch%5D%5Bregex%5D=false&columns%5B8%5D%5Bdata%5D=code&columns%5B8%5D%5Bname%5D=code.code&columns%5B8%5D%5Bsearchable%5D=true&columns%5B8%5D%5Borderable%5D=true&columns%5B8%5D%5Bsearch%5D%5Bvalue%5D=&columns%5B8%5D%5Bsearch%5D%5Bregex%5D=false&columns%5B9%5D%5Bdata%5D=id&columns%5B9%5D%5Bname%5D=id&columns%5B9%5D%5Bsearchable%5D=false&columns%5B9%5D%5Borderable%5D=true&columns%5B9%5D%5Bsearch%5D%5Bvalue%5D=&columns%5B9%5D%5Bsearch%5D%5Bregex%5D=false&order%5B0%5D%5Bcolumn%5D=9&order%5B0%5D%5Bdir%5D=desc&start={start}&length=120&search%5Bvalue%5D=&search%5Bregex%5D=false&author=&port=&type=&tag=&platform=&_={t}'
        headers = """
        accept: application/json, text/javascript, */*; q=0.01
        accept-encoding: gzip, deflate, br
        accept-language: zh-CN,zh;q=0.9
        cache-control: no-cache
        pragma: no-cache
        referer: https://www.exploit-db.com/
        user-agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36
        x-requested-with: XMLHttpRequest"""
        html = self.ha.getstring(url, headers=headers)
        jshtml = json.loads(html)
        if not jshtml['data']:
            return
        # print(jshtml['data'][0])
        for data in jshtml['data']:
            id = data['id']
            if self.is_expdbdata_unique(str(id) + 'exploit'):
                return
            name = data['description'][1]
            datasource = 'exploitdb'

            date_published = data['date_published']
            verified = data['verified']
            description = data['description']
            tags = []
            if data['tags']:
                tag = data['tags'][0]['title']
                tag = self.tag_mapping(tag)
                tags.append(tag)

            version = {}
            version['list'] = []
            ver = substring(name, ' ', ' - ')
            if ver:
                if '.' in ver:
                    version['list'].append(ver)

            type = data['type']['name']
            platform = data['platform_id']
            target = []
            tar = {}
            tar['type'] = type
            tar['platform'] = platform
            tar['version'] = version
            target.append(tar)

            author = {}
            author['name'] = data['author']['name']

            code = []
            if data['code']:
                for dat in data['code']:
                    co = {}
                    co['code_type'] = dat['code_type']
                    co['code'] = dat['code']
                    code.append(co)

            app = []
            if data['application_md5'] and data['application_path']:
                ap = {}
                application_md5 = data['application_md5']
                ap['name'] = substring(application_md5, '<a href="/apps/', '"')
                ap['url'] = 'https://www.exploit-db.com/apps/' + ap['name']
                ap['path'] = self.download_app(ap['url'], id, ap['name'])
                app.append(ap)

            exploit = []
            exp = {}
            exp['name'] = str(id) + '.txt'
            exp['url'] = 'https://www.exploit-db.com/download/' + str(id)
            exp['path'] = self.download_exploit(exp['url'], id, exp['name'])
            exploit.append(exp)

            res = {}
            res['name'] = name
            res['datasource'] = datasource
            res['id'] = str(id)
            res['date_published'] = date_published
            res['verified'] = verified
            res['description'] = description
            res['tags'] = tags
            res['target'] = target

            res['author'] = author
            res['code'] = code
            res['app'] = app
            res['exploit'] = exploit
            self.write_text(res, 'iscan_expdb')

            # with open(f'./exploit/{id}.iscan_expdb', 'w') as f:
            #     f.write(json.dumps(res))
            self.store_expdbdata_unique(str(id) + 'exploit')

    def download_exploit(self, url, id, name):
        failnum = 0
        while True:
            try:
                headers = f"""
            accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3
            accept-encoding: gzip, deflate, br
            accept-language: zh-CN,zh;q=0.9
            cache-control: no-cache
            pragma: no-cache
            referer: https://www.exploit-db.com/exploits/{id}
            upgrade-insecure-requests: 1
            user-agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36"""
                html = self.ha.get_response_stream(url, headers=headers)
                # with open(f'./exploit/{id}.iscan_expdb_exp', 'w') as f:
                description = f'datasource: exploitdb\nid: {id}\nname: {name}\nurl:{url}\n'
                data = html.read()
                outname = self.write_text_binary(description, data, 'iscan_expdb_exp')
                print(f"Output data, filename:{outname}")
                if failnum != 0:
                    self._logger.info(f'ID: {id} try download expdb_exp again success！')
                return outname

            except Exception:
                failnum += 1
                self._logger.error(f'ID: {id} download expdb_exp error: {traceback.format_exc()}\ntry download again!')
                if failnum > 3:
                    self._logger.info(f'ID: {id} download expdb_exp error over 3 times!')
                    return None
                time.sleep(3)

        # f.write(description)
        #
        # with open(f'./exploit/{id}.iscan_expdb_exp', 'ab') as f:
        #     f.write(html.read())

    def download_app(self, url, id, name):
        failnum = 0
        while True:
            try:
                headers = f"""
        accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3
        accept-encoding: gzip, deflate, br
        accept-language: zh-CN,zh;q=0.9
        cache-control: no-cache
        pragma: no-cache
        referer: https://www.exploit-db.com/exploits/{id}
        upgrade-insecure-requests: 1
        user-agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36"""
                html = self.ha.get_response_stream(url, headers=headers)
                # with open(f'./exploit/{id}.iscan_expdb_app', 'w') as f:
                description = f'datasource: exploitdb\nid: {id}\nname: {name}\nurl:{url}\n'
                # f.write(description)
                data = html.read()
                # with open(f'./exploit/{id}.iscan_expdb_app', 'ab') as f:
                #     f.write(html.read())
                outname = self.write_text_binary(description, data, 'iscan_expdb_app')
                print(f"Output data, filename:{outname}")
                if failnum != 0:
                    self._logger.info(f'ID: {id} try download expdb_app again success！')
                return outname
            except Exception:
                failnum += 1
                self._logger.error(f'ID: {id} download expdb_app error: {traceback.format_exc()}\ntry download again!')
                if failnum > 3:
                    self._logger.info(f'ID: {id} download expdb_app error over 3 times!')
                    return None
                time.sleep(3)

    def run(self):
        got = False
        none_count = 0
        while True:
            try:
                got = False
                draw, start = self.page_queue.get(timeout=3)
                got = True

                self.get_onepage(draw, start)

            except queue.Empty:
                none_count += 1
                if none_count >= 5:
                    break
                time.sleep(5)
            except Exception:
                print("获取出错: page={} error={}".format(draw, traceback.format_exc()))
            finally:
                if got:
                    self.page_queue.task_done()

    def __del__(self):
        print("EXPdb misson accomplished")

    def start(self):
        self.get_url()
        ths = [threading.Thread(target=self.run, name=f'thread{i}') for i in range(7)]
        for el in ths:
            el.start()
        for el in ths:
            el.join()
